{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roomRegress_clean.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJemkSLu/prGwCy09kpLyT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sulphatet/GetARoom_MLHackathlon/blob/main/roomRegress_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5QtK8heArq3",
        "outputId": "46d24176-3942-4bd1-f196-29a8fe0cab76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DFTN3dXwAygW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =pd.read_csv(\"drive/My Drive/Data/train_DE1.csv\")\n",
        "test_data =pd.read_csv(\"drive/My Drive/Data/test_DE1.csv\")"
      ],
      "metadata": {
        "id": "KIHAOH91B3I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train,data_test = train_test_split(data)"
      ],
      "metadata": {
        "id": "3kM8KUvIB5Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "# now you can import normally from sklearn.impute\n",
        "from sklearn.impute import KNNImputer \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data_train['Furnishing'] = data_train['Furnishing'].replace(['Semi_Furnished', 'Unfurnished', 'Fully Furnished'],[1,2,3])\n",
        "data_train['Property_Type'] = data['Property_Type'].replace(['Apartment', 'Bungalow', 'Single-family home', 'Duplex','#R%$G&867', 'Container Home'],[1,2,3,4,0,5])\n",
        "data_train['Water_Supply'] = data_train['Water_Supply'].replace(['Once in a day - Morning', 'Once in a day - Evening', 'All time','NOT MENTIONED', 'Once in two days'],[1,2,3,0,4])\n",
        "data_train['Crime_Rate'] = data_train['Crime_Rate'].replace(['Slightly below average', 'Well below average','Well above average',  'Slightly above average'],[1,2,3,4])\n",
        "data_train['Dust_and_Noise'] = data['Dust_and_Noise'].replace(['Medium',  'High', 'Low'],[2,3,1])\n",
        "data_train['Power_Backup'] = data['Power_Backup'].replace(['No', 'Yes','NOT MENTIONED'],[0,1,-1])\n",
        "#data_train['Frequency_of_Powercuts'] = data['Frequency_of_Powercuts'].replace([np.NaN]],[0.5])\n",
        "\n",
        "numeric=['Furnishing', 'Property_Type', 'Water_Supply','Crime_Rate','Dust_and_Noise','Power_Backup']\n",
        "\n",
        "#sc = StandardScaler()\n",
        "#data_train[numeric]=sc.fit_transform(data_train[numeric])\n",
        "\n",
        "#data_train = data_train.replace(np.NaN,0)\n",
        "\n",
        "X_train = data_train.iloc[:,1:-1]\n",
        "si = KNNImputer()\n",
        "imp_mean = si.fit(X_train)\n",
        "X_train = imp_mean.transform(X_train)\n",
        "\n",
        "\n",
        "\n",
        "Y_train = data_train['Habitability_score']"
      ],
      "metadata": {
        "id": "XQFslSWRB-h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test['Furnishing'] = data['Furnishing'].replace(['Semi_Furnished', 'Unfurnished', 'Fully Furnished'],[1,2,3])\n",
        "data_test['Property_Type'] = data['Property_Type'].replace(['Apartment', 'Bungalow', 'Single-family home', 'Duplex','#R%$G&867', 'Container Home'],[1,2,3,4,0,5])\n",
        "data_test['Water_Supply'] = data['Water_Supply'].replace(['Once in a day - Morning', 'Once in a day - Evening', 'All time','NOT MENTIONED', 'Once in two days'],[1,2,3,0,4])\n",
        "data_test['Crime_Rate'] = data['Crime_Rate'].replace(['Slightly below average', 'Well below average','Well above average',  'Slightly above average'],[1,2,3,4])\n",
        "data_test['Dust_and_Noise'] = data['Dust_and_Noise'].replace(['Medium',  'High', 'Low'],[2,3,1])\n",
        "data_test['Power_Backup'] = data['Power_Backup'].replace(['No', 'Yes','NOT MENTIONED'],[0,1,-1])\n",
        "#data_train['Frequency_of_Powercuts'] = data['Frequency_of_Powercuts'].replace([np.NaN]],[0.5])\n",
        "\n",
        "#data_test[numeric]=sc.fit_transform(data_test[numeric])\n",
        "#data_test = data_test.replace(np.NaN,0)\n",
        "X_test = data_test.iloc[:,1:-1]\n",
        "\n",
        "si = KNNImputer()\n",
        "imp_mean = si.fit(X_test)\n",
        "X_test = imp_mean.transform(X_test)\n",
        "\n",
        "Y_test = data_test['Habitability_score'] "
      ],
      "metadata": {
        "id": "VB3qiZc0CB9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = LinearRegression()\n",
        "clf1 = model.fit(X_train,Y_train)\n",
        "model = RandomForestRegressor()\n",
        "clf2 = model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "q0FL0zkDCEXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "KnhCKNaBCHN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = clf2.predict(X_test)\n",
        "print(r2_score(Y_test,Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnJzLN3hCSrB",
        "outputId": "cdd2d057-c085-4b1d-c981-ff5a263260db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8244727844777572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import seaborn as sns\n",
        "#sns.pairplot(data=data_train, diag_kind='kde')"
      ],
      "metadata": {
        "id": "6M9UHHy7CU0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xg\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#generic function to fit model and return metrics for every algorithm\n",
        "def boost_models(x):\n",
        "    #transforming target variable through quantile transformer\n",
        "    regr_trans = TransformedTargetRegressor(regressor=x, transformer=None)\n",
        "    regr_trans.fit(X_train, Y_train)\n",
        "    yhat = regr_trans.predict(X_test)\n",
        "    algoname= x.__class__.__name__\n",
        "    return algoname, round(r2_score(Y_test, yhat),3), round(mean_absolute_error(Y_test, yhat),2), round(np.sqrt(mean_squared_error(Y_test, yhat)),2)\n",
        "\n",
        "algo=[GradientBoostingRegressor(), lgbm.LGBMRegressor(), xg.XGBRFRegressor()]\n",
        "score=[]\n",
        "for a in algo:\n",
        "    score.append(boost_models(a))\n",
        "\n",
        " #Collate all scores in a table\n",
        "pd.DataFrame(score, columns=['Model', 'Score', 'MAE', 'RMSE'])"
      ],
      "metadata": {
        "id": "FAfIB9NaLHc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "myJovhHKMgyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}